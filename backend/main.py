from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import os
from dotenv import load_dotenv
from translator_service import TranslationService
from unified_prompt_service import UnifiedPromptService
from pdf_importer import create_vector_store, CONNECTION_STRING, COLLECTION_NAME
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import PGVector

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
translation_service = TranslationService()
unified_prompt_service = UnifiedPromptService()

# ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
vector_store = None
try:
    embeddings = HuggingFaceEmbeddings(
        model_name='nlpai-lab/KURE-v1',
        model_kwargs={'device': 'cpu'}
    )
    vector_store = PGVector(
        collection_name=COLLECTION_NAME,
        connection_string=CONNECTION_STRING,
        embedding_function=embeddings
    )
    print("âœ… LangChain ë²¡í„° ìŠ¤í† ì–´ ì—°ê²° ì„±ê³µ")
except Exception as e:
    print(f"âš ï¸ ë²¡í„° ìŠ¤í† ì–´ ì—°ê²° ì‹¤íŒ¨: {e}")
    print("ğŸ“ PDF ë°ì´í„°ë¥¼ ë¨¼ì € import í•´ì£¼ì„¸ìš”: python pdf_importer.py")

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
chat_history = []

# ìš”ì²­/ì‘ë‹µ ëª¨ë¸
class ChatMessage(BaseModel):
    message: str

class ChatResponse(BaseModel):
    response: str
    success: bool

def get_chat_context(current_message: str) -> str:
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¥ë½ êµ¬ì„±"""
    if not chat_history:
        return current_message
    
    # ìµœê·¼ 3ê°œ ëŒ€í™”ë§Œ ì‚¬ìš© (ë§¥ë½ ìœ ì§€í•˜ë©´ì„œ ë©”ëª¨ë¦¬ ì ˆì•½)
    recent_history = chat_history[-3:]
    context = ""
    
    for msg in recent_history:
        context += f"ì‚¬ìš©ì: {msg['user']}\n"
        context += f"ì±—ë´‡: {msg['bot']}\n"
    
    context += f"ì‚¬ìš©ì: {current_message}\n"
    return context

def update_chat_history(user_message: str, bot_response: str):
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸"""
    chat_history.append({
        'user': user_message,
        'bot': bot_response
    })
    
    # ìµœê·¼ 10ê°œ ëŒ€í™”ë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ ì ˆì•½)
    if len(chat_history) > 10:
        chat_history[:] = chat_history[-10:]

def search_similar_documents(query: str, top_k: int = 3) -> list:
    """LangChain ë²¡í„° ìŠ¤í† ì–´ì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰"""
    if not vector_store:
        return []
    
    try:
        print(f"ğŸ” RAG ê²€ìƒ‰: '{query}'")
        
        # ë‹¨ìˆœ ìœ ì‚¬ë„ ê²€ìƒ‰ (3ê°œ ë¬¸ì„œ)
        docs = vector_store.similarity_search(query, k=top_k)
        
        # ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œ
        reference_docs = []
        for i, doc in enumerate(docs, 1):
            content = doc.page_content[:500] + "..." if len(doc.page_content) > 500 else doc.page_content
            reference_docs.append(f"ë¬¸ì„œ {i}: {content}")
            print(f"ğŸ“„ ë¬¸ì„œ {i}: {content[:100]}...")
        
        print(f"âœ… ì„ íƒëœ ë¬¸ì„œ: {len(reference_docs)}ê°œ")
        return reference_docs
        
    except Exception as e:
        print(f"âŒ RAG ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

@app.post("/api/chat", response_model=ChatResponse)
async def chat_with_gemini(request: ChatMessage):
    try:
        print(f"ë°›ì€ ë©”ì‹œì§€: {request.message}")
        
        # ì–¸ì–´ ê°ì§€ ë° ë²ˆì—­
        translated_question, detected_lang, needs_translation = translation_service.detect_and_translate(request.message)
        
        # ëŒ€í™” ë§¥ë½ êµ¬ì„±
        chat_context = get_chat_context(translated_question)
        print(f"ëŒ€í™” ë§¥ë½ ê¸¸ì´: {len(chat_context)} ë¬¸ì")
        
        # # LangChain RAGë¡œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ (ìƒìœ„ 3ê°œ)
        reference_docs = search_similar_documents(translated_question, top_k=3)
        
        # í†µí•©ëœ í”„ë¡¬í”„íŠ¸ ì„œë¹„ìŠ¤ë¡œ ì§ˆë¬¸ ì²˜ë¦¬ (RAG ê²°ê³¼ í¬í•¨)
        response = unified_prompt_service.process_question(
            question=translated_question,
            reference_docs=reference_docs if reference_docs else None,
            chat_context=chat_context
        )
        
        # ë²ˆì—­ ì²˜ë¦¬
        if needs_translation:
            response = translation_service.translate_response(response, detected_lang)
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        update_chat_history(request.message, response)
        
        return ChatResponse(response=response, success=True)
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return ChatResponse(
            response=f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", 
            success=False
        )

@app.get("/")
async def root():
    return {"message": "ëª…ì§€ì „ë¬¸ëŒ€í•™ í•™ì‚¬ ì±—ë´‡ API (LangChain RAG + í†µí•© í”„ë¡¬í”„íŠ¸)"}

@app.post("/api/import-pdf")
async def import_pdf():
    """PDF ë°ì´í„°ë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— import"""
    try:
        global vector_store
        vector_store = create_vector_store()
        if vector_store:
            return {"message": "PDF import ì„±ê³µ!", "success": True}
        else:
            return {"message": "PDF import ì‹¤íŒ¨", "success": False}
    except Exception as e:
        return {"message": f"PDF import ì˜¤ë¥˜: {str(e)}", "success": False}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)